**判别器和生成器损耗**
在这一部分中, 我们需要定义判别器和生成器损耗, 这可以被认为是此实现中最棘手的部分。
我们知道, 生成器试图复制原始图像。判别器像一名法官那样工作, 从生成器接收图像和原始输入图像。因此, 在为每个部分设计我们的损失时, 我们需要针对两件事情。
首先, 我们需要网络的判别器部分能够区分生成器生成的假图像和来自原始的培训实例的真正图像。在训练期间, 我们将用一批被分成两类的数据输入给判别器。第一个类别是来自原始输入的图像。第二类是生成器生成的假图像。
因此, 判别器的最终一般损失将是其接受真实作为真实的能力,和检测到假的是假的的能力;那么最终的全部损失将是:
disc_loss=disc_loss_real+disc_loss_fake
```python
tf.reduce_mean(
    tf.nn.sigmoid_cross_entropy_with_logits(
        labels=tf.ones_like(disc_logits_fake),
        logits=disc_logits_fake))
因此, 我们需要计算两个损失, 才能得出最终的判别损失。        
第一种损失,disc_loss_real,从判别器和labels中得到基于logits的计算。labels是在这种情况下, 所有这个迷你批次中的所有图像都来自mmist 数据集的真正的输入图像。为了提高模型对测试集的泛化能力, 并给出更好的结果, 人们发现, 实际改变值1到0.9 更好。
这种对标签的更改引入了一种称为标签平滑的内容: 
